{"cells":[{"cell_type":"markdown","metadata":{"id":"v5tDiSqVjHux"},"source":["![](https://github.com/rajeevratan84/ModernComputerVision/raw/main/logo_MCV_W.png)\n","\n","# **Neural Style Transfer with OpenCV**\n","\n","####**In this lesson we'll learn how to use pre-trained Models to implement Neural Style Transfer in OpenCV**\n","\n","![](https://github.com/rajeevratan84/ModernComputerVision/raw/main/NSTdemo.png)\n","\n","**About Neural Style Transfers**\n","\n","Introduced by Leon Gatys et al. in 2015, in their paper titled “[A Neural Algorithm for Artistic Style](https://arxiv.org/abs/1508.06576)”, the Neural Style Transfer algorithm went viral resulting in an explosion of further work and mobile apps.\n","\n","Neural Style Transfer enables the artistic style of an image to be applied to another image! It copies the color patterns, combinations, and brush strokes of the original source image and applies it to your input image. And is one the most impressive implementations of Neural Networks in my opinion.\n","\n","![](https://github.com/rajeevratan84/ModernComputerVision/raw/main/NST.png)"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12842,"status":"ok","timestamp":1661493236920,"user":{"displayName":"Alien Editz","userId":"03181622927197882991"},"user_tz":-330},"id":"YMa6uOqSq1JQ","outputId":"41397ced-78d1-4752-d023-68c05dfd1297"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-08-26 05:53:44--  https://moderncomputervision.s3.eu-west-2.amazonaws.com/NeuralStyleTransfer.zip\n","Resolving moderncomputervision.s3.eu-west-2.amazonaws.com (moderncomputervision.s3.eu-west-2.amazonaws.com)... 52.95.143.14\n","Connecting to moderncomputervision.s3.eu-west-2.amazonaws.com (moderncomputervision.s3.eu-west-2.amazonaws.com)|52.95.143.14|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 186982232 (178M) [application/zip]\n","Saving to: ‘NeuralStyleTransfer.zip’\n","\n","NeuralStyleTransfer 100%[===================>] 178.32M  30.5MB/s    in 6.8s    \n","\n","2022-08-26 05:53:51 (26.4 MB/s) - ‘NeuralStyleTransfer.zip’ saved [186982232/186982232]\n","\n"]}],"source":["# import the necessary packages\n","import numpy as np\n","import time\n","import cv2\n","import os\n","from os import listdir\n","from os.path import isfile, join\n","from matplotlib import pyplot as plt \n","\n","# Define our imshow function \n","def imshow(title = \"Image\", image = None, size = 10):\n","    w, h = image.shape[0], image.shape[1]\n","    aspect_ratio = w/h\n","    plt.figure(figsize=(size * aspect_ratio,size))\n","    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","    plt.title(title)\n","    plt.show()\n","\n","# Download and unzip our images and YOLO files\n","!wget https://moderncomputervision.s3.eu-west-2.amazonaws.com/NeuralStyleTransfer.zip\n","!unzip -qq NeuralStyleTransfer.zip"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1078,"status":"ok","timestamp":1661493239703,"user":{"displayName":"Alien Editz","userId":"03181622927197882991"},"user_tz":-330},"id":"n0fQDP3UxJ3A","outputId":"c40dd326-0b71-41de-b2e3-14c542484d4b"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-08-26 05:53:58--  https://github.com/rajeevratan84/ModernComputerVision/raw/main/city.jpg\n","Resolving github.com (github.com)... 140.82.114.4\n","Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/rajeevratan84/ModernComputerVision/main/city.jpg [following]\n","--2022-08-26 05:53:59--  https://raw.githubusercontent.com/rajeevratan84/ModernComputerVision/main/city.jpg\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 392132 (383K) [image/jpeg]\n","Saving to: ‘city.jpg’\n","\n","city.jpg            100%[===================>] 382.94K  --.-KB/s    in 0.03s   \n","\n","2022-08-26 05:53:59 (11.1 MB/s) - ‘city.jpg’ saved [392132/392132]\n","\n"]}],"source":["!wget https://github.com/rajeevratan84/ModernComputerVision/raw/main/city.jpg"]},{"cell_type":"markdown","metadata":{"id":"TT7y4eiR1uwU"},"source":["### **Implement Neural Style Transfer using pretrained Models**\n","\n","We use pretrained t7 PyTorch models that can be imported using ``cv2.dnn.readNetFromTouch()```\n","\n","These models we're using come from the paper *Perceptual Losses for Real-Time Style Transfer and Super-Resolution* by Johnson et al. \n","\n","They improved proposing a Neural Style Transfer algorithm that performed 3 times faster by using a super-resolution-like problem based on perceptual loss function."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1Fn6W7VYaXw4TmQuvPkGNuTeWAejPrWjK"},"id":"Hza0jpipvl8U","outputId":"061b4597-0bde-4012-892c-201c856cd159","executionInfo":{"status":"ok","timestamp":1661493287494,"user_tz":-330,"elapsed":45383,"user":{"displayName":"Alien Editz","userId":"03181622927197882991"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# Load our t7 neural transfer models\n","model_file_path = \"NeuralStyleTransfer/models/\"\n","model_file_paths = [f for f in listdir(model_file_path) if isfile(join(model_file_path, f))]\n","\n","# Load our test image\n","img = cv2.imread(\"city.jpg\")\n","\n","# Loop through and applying each model style our input image\n","for (i,model) in enumerate(model_file_paths):\n","    # print the model being used\n","    print(str(i+1) + \". Using Model: \" + str(model)[:-3])    \n","    style = cv2.imread(\"NeuralStyleTransfer/art/\"+str(model)[:-3]+\".jpg\")\n","    # loading our neural style transfer model \n","    neuralStyleModel = cv2.dnn.readNetFromTorch(model_file_path+ model)\n","\n","    # Let's resize to a fixed height of 640 (feel free to change)\n","    height, width = int(img.shape[0]), int(img.shape[1])\n","    newWidth = int((640 / height) * width)\n","    resizedImg = cv2.resize(img, (newWidth, 640), interpolation = cv2.INTER_AREA)\n","\n","    # Create our blob from the image and then perform a forward pass run of the network\n","    inpBlob = cv2.dnn.blobFromImage(resizedImg, 1.0, (newWidth, 640), (103.939, 116.779, 123.68), swapRB=False, crop=False)\n","\n","    neuralStyleModel.setInput(inpBlob)\n","    output = neuralStyleModel.forward()\n","\n","    # Reshaping the output tensor, adding back  the mean subtraction and re-ordering the channels \n","    output = output.reshape(3, output.shape[2], output.shape[3])\n","    output[0] += 103.939\n","    output[1] += 116.779\n","    output[2] += 123.68\n","    output /= 255\n","    output = output.transpose(1, 2, 0)\n","    \n","    #Display our original image, the style being applied and the final Neural Style Transfer\n","    imshow(\"Original\", img)\n","    imshow(\"Style\", style)\n","    imshow(\"Neural Style Transfers\", output)"]},{"cell_type":"markdown","metadata":{"id":"5DeMooEJ6KMl"},"source":["## **Using the ECCV16 Updated NST Algorithm**\n","\n","In Ulyanov et al.’s 2017 publication, *Instance Normalization: The Missing Ingredient for Fast Stylization*, it was found that swapping batch normalization for instance normalization (and applying instance normalization at both training and testing), leads to even faster real-time performance and arguably more aesthetically pleasing results as well.\n","\n","Let's now use the models used by Johnson et al. in their ECCV paper.\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"yrJE2n8J6Jo0","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1ac1MU2CY81B-Jot5GbG0qW58AQoDU8h3"},"executionInfo":{"status":"ok","timestamp":1661493333186,"user_tz":-330,"elapsed":23643,"user":{"displayName":"Alien Editz","userId":"03181622927197882991"}},"outputId":"239df09e-6bce-4926-a6b4-d43ba4c237c1"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# Load our t7 neural transfer models\n","model_file_path = \"NeuralStyleTransfer/models/ECCV16/\"\n","model_file_paths = [f for f in listdir(model_file_path) if isfile(join(model_file_path, f))]\n","\n","# Load our test image\n","img = cv2.imread(\"city.jpg\")\n","\n","# Loop through and applying each model style our input image\n","for (i,model) in enumerate(model_file_paths):\n","    # print the model being used\n","    print(str(i+1) + \". Using Model: \" + str(model)[:-3])    \n","    style = cv2.imread(\"NeuralStyleTransfer/art/\"+str(model)[:-3]+\".jpg\")\n","    # loading our neural style transfer model \n","    neuralStyleModel = cv2.dnn.readNetFromTorch(model_file_path+ model)\n","\n","    # Let's resize to a fixed height of 640 (feel free to change)\n","    height, width = int(img.shape[0]), int(img.shape[1])\n","    newWidth = int((640 / height) * width)\n","    resizedImg = cv2.resize(img, (newWidth, 640), interpolation = cv2.INTER_AREA)\n","\n","    # Create our blob from the image and then perform a forward pass run of the network\n","    inpBlob = cv2.dnn.blobFromImage(resizedImg, 1.0, (newWidth, 640), (103.939, 116.779, 123.68), swapRB=False, crop=False)\n","\n","    neuralStyleModel.setInput(inpBlob)\n","    output = neuralStyleModel.forward()\n","\n","    # Reshaping the output tensor, adding back  the mean subtraction and re-ordering the channels \n","    output = output.reshape(3, output.shape[2], output.shape[3])\n","    output[0] += 103.939\n","    output[1] += 116.779\n","    output[2] += 123.68\n","    output /= 255\n","    output = output.transpose(1, 2, 0)\n","    \n","    #Display our original image, the style being applied and the final Neural Style Transfer\n","    imshow(\"Original\", img)\n","    imshow(\"Style\", style)\n","    imshow(\"Neural Style Transfers\", output)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1661493333186,"user":{"displayName":"Alien Editz","userId":"03181622927197882991"},"user_tz":-330},"id":"KwxO2qXuxQsp","outputId":"05e005e4-a0ca-4ecf-b5fa-cf1d3c03eb86"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-08-26 05:55:32--  https://github.com/rajeevratan84/ModernComputerVision/raw/main/dj.mp4\n","Resolving github.com (github.com)... 140.82.112.3\n","Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/rajeevratan84/ModernComputerVision/main/dj.mp4 [following]\n","--2022-08-26 05:55:32--  https://raw.githubusercontent.com/rajeevratan84/ModernComputerVision/main/dj.mp4\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 174741 (171K) [application/octet-stream]\n","Saving to: ‘dj.mp4’\n","\n","dj.mp4              100%[===================>] 170.65K  --.-KB/s    in 0.02s   \n","\n","2022-08-26 05:55:32 (7.32 MB/s) - ‘dj.mp4’ saved [174741/174741]\n","\n"]}],"source":["!wget https://github.com/rajeevratan84/ModernComputerVision/raw/main/dj.mp4"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":91965,"status":"ok","timestamp":1661493477833,"user":{"displayName":"Alien Editz","userId":"03181622927197882991"},"user_tz":-330},"id":"N4T20P3hyi2R","outputId":"dcbe636d-d4f5-4a74-aa88-24ebc65bd99f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Completed 1 Frame(s)\n","Completed 2 Frame(s)\n","Completed 3 Frame(s)\n","Completed 4 Frame(s)\n","Completed 5 Frame(s)\n","Completed 6 Frame(s)\n","Completed 7 Frame(s)\n","Completed 8 Frame(s)\n","Completed 9 Frame(s)\n","Completed 10 Frame(s)\n","Completed 11 Frame(s)\n","Completed 12 Frame(s)\n","Completed 13 Frame(s)\n","Completed 14 Frame(s)\n","Completed 15 Frame(s)\n","Completed 16 Frame(s)\n","Completed 17 Frame(s)\n","Completed 18 Frame(s)\n","Completed 19 Frame(s)\n","Completed 20 Frame(s)\n","Completed 21 Frame(s)\n","Completed 22 Frame(s)\n","Completed 23 Frame(s)\n","Completed 24 Frame(s)\n","Completed 25 Frame(s)\n","Completed 26 Frame(s)\n","Completed 27 Frame(s)\n","Completed 28 Frame(s)\n","Completed 29 Frame(s)\n","Completed 30 Frame(s)\n","Completed 31 Frame(s)\n","Completed 32 Frame(s)\n","Completed 33 Frame(s)\n"]}],"source":["# Load our t7 neural transfer models\n","model_file_path = \"NeuralStyleTransfer/models/ECCV16/starry_night.t7\"\n","\n","# Load video stream, long clip\n","cap = cv2.VideoCapture('dj.mp4')\n","\n","# Get the height and width of the frame (required to be an interger)\n","w = int(cap.get(3)) \n","h = int(cap.get(4))\n","\n","# Define the codec and create VideoWriter object. The output is stored in '*.avi' file.\n","out = cv2.VideoWriter('NST_Starry_Night.avi', cv2.VideoWriter_fourcc('M','J','P','G'), 30, (w, h))\n","\n","# Loop through and applying each model style our input image\n","#for (i,model) in enumerate(model_file_paths):\n","style = cv2.imread(\"NeuralStyleTransfer/art/starry_night.jpg\")\n","i = 0\n","while(1):\n","\n","    ret, img = cap.read()\n","\n","    if ret == True:  \n","      i += 1\n","      print(\"Completed {} Frame(s)\".format(i))\n","      # loading our neural style transfer model \n","      neuralStyleModel = cv2.dnn.readNetFromTorch(model_file_path)\n","\n","      # Let's resize to a fixed height of 640 (feel free to change)\n","      height, width = int(img.shape[0]), int(img.shape[1])\n","      newWidth = int((640 / height) * width)\n","      resizedImg = cv2.resize(img, (newWidth, 640), interpolation = cv2.INTER_AREA)\n","\n","      # Create our blob from the image and then perform a forward pass run of the network\n","      inpBlob = cv2.dnn.blobFromImage(resizedImg, 1.0, (newWidth, 640),\n","                                (103.939, 116.779, 123.68), swapRB=False, crop=False)\n","\n","      neuralStyleModel.setInput(inpBlob)\n","      output = neuralStyleModel.forward()\n","\n","      # Reshaping the output tensor, adding back  the mean subtraction \n","      # and re-ordering the channels \n","      output = output.reshape(3, output.shape[2], output.shape[3])\n","      output[0] += 103.939\n","      output[1] += 116.779\n","      output[2] += 123.68\n","      output /= 255\n","      output = output.transpose(1, 2, 0)\n","      \n","      #Display our original image, the style being applied and the final Neural Style Transfer\n","      #imshow(\"Original\", img)\n","      #imshow(\"Style\", style)\n","      #imshow(\"Neural Style Transfers\", output)\n","      vid_output = (output * 255).astype(np.uint8)\n","      vid_output = cv2.resize(vid_output, (w, h), interpolation = cv2.INTER_AREA)\n","      out.write(vid_output)\n","    else:\n","      break\n","\n","cap.release()\n","out.release()"]},{"cell_type":"markdown","source":["## **Display your video**"],"metadata":{"id":"lT2qx3vjkmw_"}},{"cell_type":"code","source":["!ffmpeg -i /content/NST_Starry_Night.avi NST_Starry_Night.mp4 -y"],"metadata":{"id":"Xoh5tjVlkivx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661493494884,"user_tz":-330,"elapsed":3474,"user":{"displayName":"Alien Editz","userId":"03181622927197882991"}},"outputId":"81f6ebdd-ccd4-4fcb-c122-0e04aa88e3cb"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n","  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n","  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n","  libavutil      55. 78.100 / 55. 78.100\n","  libavcodec     57.107.100 / 57.107.100\n","  libavformat    57. 83.100 / 57. 83.100\n","  libavdevice    57. 10.100 / 57. 10.100\n","  libavfilter     6.107.100 /  6.107.100\n","  libavresample   3.  7.  0 /  3.  7.  0\n","  libswscale      4.  8.100 /  4.  8.100\n","  libswresample   2.  9.100 /  2.  9.100\n","  libpostproc    54.  7.100 / 54.  7.100\n","Input #0, avi, from '/content/NST_Starry_Night.avi':\n","  Metadata:\n","    encoder         : Lavf58.76.100\n","  Duration: 00:00:01.10, start: 0.000000, bitrate: 27634 kb/s\n","    Stream #0:0: Video: mjpeg (MJPG / 0x47504A4D), yuvj420p(pc, bt470bg/unknown/unknown), 640x360, 28449 kb/s, 30 fps, 30 tbr, 30 tbn, 30 tbc\n","Stream mapping:\n","  Stream #0:0 -> #0:0 (mjpeg (native) -> h264 (libx264))\n","Press [q] to stop, [?] for help\n","\u001b[1;36m[libx264 @ 0x564c1fa77e00] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n","\u001b[1;36m[libx264 @ 0x564c1fa77e00] \u001b[0mprofile High, level 3.0\n","\u001b[1;36m[libx264 @ 0x564c1fa77e00] \u001b[0m264 - core 152 r2854 e9a5903 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n","Output #0, mp4, to 'NST_Starry_Night.mp4':\n","  Metadata:\n","    encoder         : Lavf57.83.100\n","    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuvj420p(pc), 640x360, q=-1--1, 30 fps, 15360 tbn, 30 tbc\n","    Metadata:\n","      encoder         : Lavc57.107.100 libx264\n","    Side data:\n","      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n","frame=   33 fps= 16 q=-1.0 Lsize=    1718kB time=00:00:01.00 bitrate=14070.3kbits/s speed=0.497x    \n","video:1717kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.058764%\n","\u001b[1;36m[libx264 @ 0x564c1fa77e00] \u001b[0mframe I:2     Avg QP:31.19  size: 62197\n","\u001b[1;36m[libx264 @ 0x564c1fa77e00] \u001b[0mframe P:28    Avg QP:32.42  size: 52763\n","\u001b[1;36m[libx264 @ 0x564c1fa77e00] \u001b[0mframe B:3     Avg QP:32.72  size: 51805\n","\u001b[1;36m[libx264 @ 0x564c1fa77e00] \u001b[0mconsecutive B-frames: 84.8%  6.1%  9.1%  0.0%\n","\u001b[1;36m[libx264 @ 0x564c1fa77e00] \u001b[0mmb I  I16..4:  0.0% 90.2%  9.8%\n","\u001b[1;36m[libx264 @ 0x564c1fa77e00] \u001b[0mmb P  I16..4:  0.2% 76.2% 17.3%  P16..4:  1.7%  2.8%  1.7%  0.0%  0.0%    skip: 0.0%\n","\u001b[1;36m[libx264 @ 0x564c1fa77e00] \u001b[0mmb B  I16..4:  0.0% 68.9% 20.1%  B16..8:  3.1%  4.7%  2.2%  direct: 1.1%  skip: 0.0%  L0:59.4% L1:17.3% BI:23.2%\n","\u001b[1;36m[libx264 @ 0x564c1fa77e00] \u001b[0m8x8 transform intra:81.5% inter:59.6%\n","\u001b[1;36m[libx264 @ 0x564c1fa77e00] \u001b[0mcoded y,uvDC,uvAC intra: 99.2% 99.6% 97.1% inter: 99.0% 95.9% 65.9%\n","\u001b[1;36m[libx264 @ 0x564c1fa77e00] \u001b[0mi16 v,h,dc,p: 26% 64%  0%  9%\n","\u001b[1;36m[libx264 @ 0x564c1fa77e00] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 10% 18% 18%  6%  8%  9%  9%  6% 16%\n","\u001b[1;36m[libx264 @ 0x564c1fa77e00] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 12% 14% 12%  8% 11% 11% 11%  7% 14%\n","\u001b[1;36m[libx264 @ 0x564c1fa77e00] \u001b[0mi8c dc,h,v,p: 58% 19% 11% 12%\n","\u001b[1;36m[libx264 @ 0x564c1fa77e00] \u001b[0mWeighted P-Frames: Y:14.3% UV:10.7%\n","\u001b[1;36m[libx264 @ 0x564c1fa77e00] \u001b[0mref P L0: 32.4% 11.8% 31.9% 21.8%  2.1%\n","\u001b[1;36m[libx264 @ 0x564c1fa77e00] \u001b[0mref B L0: 77.1% 22.9%\n","\u001b[1;36m[libx264 @ 0x564c1fa77e00] \u001b[0mkb/s:12779.50\n"]}]},{"cell_type":"code","source":["from IPython.display import HTML\n","from base64 import b64encode\n"," \n","video_path = '/content/NST_Starry_Night.mp4'\n"," \n","mp4 = open(video_path, \"rb\").read()\n","data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","HTML(f\"\"\"\n","<video width=600 controls><source src=\"{data_url}\" type=\"video/mp4\">\n","</video>\"\"\")"],"metadata":{"id":"S5k0A0IBkjgs","colab":{"base_uri":"https://localhost:8080/","height":359,"output_embedded_package_id":"1I136KNYJ0QfECwifZ8TKUFihVmCQwt1h"},"executionInfo":{"status":"ok","timestamp":1661493500007,"user_tz":-330,"elapsed":2371,"user":{"displayName":"Alien Editz","userId":"03181622927197882991"}},"outputId":"f484d367-e71a-45ff-cc3d-91609096bd8e"},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"btppBi7XIKhp"},"source":["## **Want to train your own NST Model?**\n","\n","## **Look at later sections of the course where we take a look at Implementing our very own Deep Learning NST Algorithm**\n","\n","Alternatively, give this github repo a shot and try it yourself - https://github.com/jcjohnson/fast-neural-style"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"34. Neural Style Transfer with OpenCV.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}